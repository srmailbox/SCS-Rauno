---
title: "Compare New Sample to Original Sample"
author: "Serje Robidoux"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.height=6, fig.width=6)
library(ggplot2)
library(ggExtra)
library(gridExtra)
library(ggpubr)
library(psych)
library(kableExtra)
library(pander)
library(readxl)
library(mclust)
```

# Intro

We have new samples of Maze scores from three schools, with only the three final Mazes (Math 3, English 2, and Science 2). These Mazes were administered earlier in the year than the initial sample.

```{r readData}
# First step is to read in the data
rawDataFile = 'ACUReadingInitiative.scsRaw.RDat'
if(file.exists(rawDataFile)) load(rawDataFile) else {
  scsRaw = read.csv('ACU Reading Initiative - Export - Export (2).csv'
                    , na.strings = c("Absent ", "absent ", "Absent", "absent"
                                     , "-", "NULL"))
  save(scsRaw, file=rawDataFile)
}

newDataFiles = list('DLS Revesby_edited_deid.xlsx', 'Trinity_edited_deid.xlsx', 'Marcellin Randwick 2024_edited_deid.xlsx')

newRaw=lapply(newDataFiles, read_excel, sheet='Data Entry', na="999") %>% 
  bind_rows() %>% 
  rename_with(~gsub(" ", ".", .x, fixed=T)) %>% 
  filter(!is.na(SIS.ID)) %>% 
  select(-Match, -contains("Incorrect"))

```

Note that there are two scores of 999 (one for English and one for Science) which I have recoded as missing.


```{r splitByClass}
# Just sets up the raw data
scs = scsRaw %>% rename(Test.1.Num.Incorrect= Test.1.Num.Correct.1) %>% select(-matches("PAT"), -matches("NAPLAN")) %>% 
  mutate(Course = str_extract(Class, "ENG|SCI|MAT|REL|HIS|GEO")
         , Course = ifelse(Course=="HIS", "GEO", Course)
         , Grade = str_split(Class, Course, simplify = T)[1]
         , Classroom = str_split(Class, Course, simplify = T)[2])

# First, I think we should reorganize the Test data to be long format
# Splitting both Correct and Incorrect simultaneously was a fun new thing to
# learn.
scsLong = scs %>% select(-Class) %>% 
  pivot_longer(cols = starts_with("Test"), names_to = c("Test", ".value"), names_pattern = "Test\\.(.)\\.Num.(.*)")

# Split data by Class (ENG, MATH, etc...)
scsClasses = by(scs %>% select(-Course), scs$Course, function(x) x)

# Create a separate data.frame with only PAT and NAPLAN data for each child.
scsClasses$Assessments = 
    scsRaw %>% select(SIS.ID, matches("PAT"), matches("NAPLAN")) %>% unique
#Looks ok to me.
```

# Descriptives of each Maze, by Sample

```{r testDescs}

newDescs = newRaw %>% select(-SIS.ID) %>%  
  rename_with(~gsub(".[cC]orrect", "", .x)) %>%
  describe() %>% as.data.frame %>% 
  mutate(Sample = "New") %>% 
  rownames_to_column("Maze")


oldDescs=
  lapply(scsClasses
         , function(x) 
           if(is.null(x$PAT.Reading.2022)) {
             describe(x %>% select(matches("\\.Correct")), omit=T) %>% 
               rownames_to_column('rn') %>% 
               mutate(Test = str_extract(rn, "1|2|3")
                      , Sample="Orig") %>% 
               select(Sample, Test, n, mean, sd, median, min, max, skew
                      , kurtosis) %>% as.data.frame
           }
  ) %>% bind_rows

oldDescs$Course = gl(5,3, labels = names(scsClasses)[-6])

oldDescs$Maze = paste0(oldDescs$Course, oldDescs$Test)

bind_rows(oldDescs, newDescs) %>% 
  filter(Maze %in% c("MAT3", "ENG2", "SCI2") | Sample == "New") %>% 
  select(Sample, Maze, n, mean, sd, median, min, max, skew, kurtosis) %>% arrange(Maze, Sample) %>% 
  pander
```

In all cases, the new sample produces lower scores than the original sample (as expected given the timing of the assessment). In all three cases, the differences would be highly statistically significant if we conducted t-tests.

# Correlations amongst the Mazes for the new Sample

```{r newCors}

cor(newRaw %>% rename_with(~gsub(".[cC]orrect", "", .x)) %>% select(-SIS.ID)
    , use="pairwise.complete") %>% 
  pander
```

# Clustering and Profiling

## Factor Analysis

We can't really do FA here, as we do not have enough variables to fit more than one factor.

## PCA


```{r coreprincomp}
princomp(newRaw %>% select(-SIS.ID) %>% drop_na %>% scale)[c("loadings", "sdev")]
```

No new insights: still just one general skill component. Although if we do consider Comp 2 (we shouldn't!), it loads as English vs Science (comparing to the original sample that loaded as English vs. Math/Science). Here again though, there's isn't much reason to make much of that.

## Hierarchical Clustering

As discussed, clustering is ... finicky and generally not very robust, nonetheless it might provide some insights that raise questions. Given the results above, though, I am very skeptical that we'll find much of value here.

It's also probably much too complex an approach for only 3 variables. Nonetheless...

```{r hclustcore, fig.caption = "Clustering results for the new sample"}
scs.new = newRaw %>% 
    select(-SIS.ID) %>%
    drop_na()

scs.dist = (scs.hclust = scs.new %>% 
              scale %>% data.frame) %>%  dist

scs.cmplt = hclust(scs.dist)

scs.hclust$hclust.cmplt = cutree(scs.cmplt, 6)
scs.new$hclust.cmplt = cutree(scs.cmplt, 6)

plot(scs.cmplt, labels = scs.hclust$hclust.cmplt, cex=.75)
```


There seem to be perhaps 3 or 4 clusters here, with a couple of very small groups. Let's look at how they differ:

```{r coreHClustDescriptives}

scs.hclust %>% 
    rename(Cluster = hclust.cmplt) %>% 
  group_by(Cluster) %>% 
  summarize(N = n()
            , ENG = paste0(round(mean(ENG.Correct),2)," (",round(sd(ENG.Correct),3),")")
            , MAT = paste0(round(mean(MAT.correct),2)," (",round(sd(MAT.correct),3),")")
            , SCI = paste0(round(mean(SCI.correct),2)," (",round(sd(SCI.correct),3),")")
            ) %>% 
  ungroup %>% 
  # slice(3,1,2,4,5,6) %>% 
  pander(alignment = "right", caption = "Mean z-scores (SD) by cluster.")

# scs.new %>%
#   rename(Cluster = hclust.cmplt) %>% 
#   group_by(Cluster) %>% 
#   summarize_all(function(x) 
#     paste0(round(mean(x, na.rm=T),1)," (",round(sd(x, na.rm=T),2),")")) %>% 
#   ungroup %>% 
#   # slice(3,1,2,4,5,6) %>% 
#   pander(alignment = "right", caption = "Mean and SDs of raw matrix scores by cluster.")

```

```{r coreHClustPlot}

scs.hclust %>% pivot_longer(-hclust.cmplt, names_to="matrix", values_to = "z") %>% 
  ggplot(aes(x=matrix, y=z))+
  facet_wrap(vars(hclust.cmplt), ncol=3)+
  geom_boxplot()

# scs.hclust %>%
#   mutate(id=row_number()) %>% pivot_longer(ENG_2:SCI_2, names_to="matrix", values_to = "z") %>%
#   filter(hclust.cmplt %in% c(1:3)) %>%
#   ggplot(aes(x=matrix, y=z, colour=hclust.cmplt, group=id))+
#   geom_line()+
#   scale_color_continuous(guide="none")

```

Cluster 1 (N=224, average), 2 (N=93, above average), 3 (N=5, very very high performers) and 5 (N=28, very low performers) seem to be general skill clusters. Cluster 4 (N=69) seems to be students who are somewhat poorer at Math and Science, but average at English. while Cluster 6 (N=12) appear to be students who are strong at English but average at Math and Science.

Generally this is fairly consistent with what we found in the original sample, though the smaller groups are a bit different - but we're still seeing the larger groups defined by their general ability, with a few clusters that differentiate English from Math/Sci.

\newpage

## Latent Profiles

```{r coreLPA}

scsNew = newRaw %>% #select(all_of(coreMatrices), matches("(NAPLAN|PAT)")
                             # , -matches("(Band|Profic)")) %>%
  drop_na()
scsLPA = scsNew %>% select(-SIS.ID)

scs.mclust = mclustBIC(scsLPA)

```

There are really only 2 or 3 groups here. I'll compare the two simplest models

### VEE, 2

This model allows the classes to be of different sizes (in space) but will have identical covariance structures. (They are different sizes, but have the same ratio of variances and point in the same direction.)

The figure below shows how the means and covariance matrices differ by class (depicted by the circles), along with the "most probable" class assigned to each student (colours). The table summarizes means, SDs and group sizes.

```{r coreLPAVEE2, fig.cap = "VEE, 2 results for the new sample"}
classCols = rgb(c(1,0,0, .5), c(0,0,1, .5), c(0,1,0, 0), alpha=.25)
scs.VEE2 = Mclust(scsLPA, x=scs.mclust, modelNames="VEE", G=2)
plot(x=scs.VEE2, what="class", col=classCols)
```


```{r coreLPAVEE2tbl}
merge(round(scs.VEE2$parameters$mean,1)
      , round(sqrt(apply(scs.VEE2$parameters$variance$sigma,3,diag)),1)
      , by="row.names"
      , suffixes=c(".mean", ".sd")) %>% 
  mutate(Test = Row.names
         , Group.1 = paste0(V1.mean, " (", V1.sd, ")")
         , Group.2 = paste0(V2.mean, " (", V2.sd, ")")
         # , Group.3 = paste0(V3.mean, " (", V3.sd, ")")
         ) %>% 
  select(Test, Group.1, Group.2) %>% 
  rbind(c("N", table(scs.VEE2$classification))
            , c("N wtd", round(colSums(scs.VEE2$z), 2))
) %>% 
  pander("Means and SDs for VEE,2 (new sample)")
```

```{r coreScaleLPAVEE2tbl}
scsScale.mclust = mclustBIC(scsLPA %>% scale)
scsScale.VEE2 = Mclust(scsLPA %>% scale, x=scsScale.mclust, modelNames="VEE", G=2)

merge(round(scsScale.VEE2$parameters$mean,2)
      , round(sqrt(apply(scsScale.VEE2$parameters$variance$sigma,3,diag)),3)
      , by="row.names"
      , suffixes=c(".mean", ".sd")) %>% 
  mutate(Test = Row.names
         , Group.1 = paste0(V1.mean, " (", V1.sd, ")")
         , Group.2 = paste0(V2.mean, " (", V2.sd, ")")
         # , Group.3 = paste0(V3.mean, " (", V3.sd, ")")
         ) %>% 
  select(Test, Group.1, Group.2) %>% 
  rbind(c("N", table(scsScale.VEE2$classification))
            , c("N wtd", round(colSums(scsScale.VEE2$z), 2))
) %>% 
  pander("Means and SDs (z-scores) for VEE,2 (new sample)")
```

Unsurprisingly, this just produces higher and lower scoring samples, with a small sample of above average performers separated from the general sample.

### VEE, 3

```{r coreLPAVEE3, fig.cap = "VEE, 3 results for the new sample"}
classCols = rgb(c(1,0,0, .5), c(0,0,1, .5), c(0,1,0, 0), alpha=.25)
scs.VEE3 = Mclust(scsLPA, x=scs.mclust, modelNames="VEE", G=3)
plot(x=scs.VEE3, what="class", col=classCols)
```


```{r coreLPAVEE3tbl}
merge(round(scs.VEE3$parameters$mean,1)
      , round(sqrt(apply(scs.VEE3$parameters$variance$sigma,3,diag)),1)
      , by="row.names"
      , suffixes=c(".mean", ".sd")) %>% 
  mutate(Test = Row.names
         , Group.1 = paste0(V1.mean, " (", V1.sd, ")")
         , Group.2 = paste0(V2.mean, " (", V2.sd, ")")
         , Group.3 = paste0(V3.mean, " (", V3.sd, ")")
         ) %>% 
  select(Test, Group.1, Group.2, Group.3) %>% 
  rbind(c("N", table(scs.VEE3$classification))
            , c("N wtd", round(colSums(scs.VEE3$z), 2))
) %>% 
  pander("Means and SDs for VEE,3 (new sample)")
```

```{r coreScaleLPAVEE3tbl}
scsScale.mclust = mclustBIC(scsLPA %>% scale)
scsScale.VEE3 = Mclust(scsLPA %>% scale, x=scsScale.mclust, modelNames="VEE", G=3)

merge(round(scsScale.VEE3$parameters$mean,2)
      , round(sqrt(apply(scsScale.VEE3$parameters$variance$sigma,3,diag)),3)
      , by="row.names"
      , suffixes=c(".mean", ".sd")) %>% 
  mutate(Test = Row.names
         , Group.1 = paste0(V1.mean, " (", V1.sd, ")")
         , Group.2 = paste0(V2.mean, " (", V2.sd, ")")
         , Group.3 = paste0(V3.mean, " (", V3.sd, ")")
         ) %>% 
  select(Test, Group.1, Group.2, Group.3) %>% 
  rbind(c("N", table(scsScale.VEE3$classification))
            , c("N wtd", round(colSums(scsScale.VEE3$z), 2))
) %>% 
  pander("Means and SDs (z-scores) for VEE,3 (new sample)")
```

As with the 2 group solution, this has one large "somewhat below average" group (2), but here the "higher performing" students are split on English - where one is much higher on English scores than the other (group 3 scores much higher on English, while Group 1 is below average on English, but good at Math and Science).

This differs from the original sample, where groups really only differed by their general performance.